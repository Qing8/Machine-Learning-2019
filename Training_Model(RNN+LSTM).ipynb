{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import Tensor\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"normalied_train_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop(df_train.columns[[0,1]],axis= 1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hash</th>\n",
       "      <th>trajectory_id</th>\n",
       "      <th>time_entry</th>\n",
       "      <th>time_exit</th>\n",
       "      <th>x_entry</th>\n",
       "      <th>y_entry</th>\n",
       "      <th>x_exit</th>\n",
       "      <th>y_exit</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000a8602cf2def930488dee7cdad104_1</td>\n",
       "      <td>traj_0000a8602cf2def930488dee7cdad104_1_0</td>\n",
       "      <td>-0.411531</td>\n",
       "      <td>-0.419661</td>\n",
       "      <td>-0.360248</td>\n",
       "      <td>-0.377866</td>\n",
       "      <td>2.485085</td>\n",
       "      <td>-0.377866</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000a8602cf2def930488dee7cdad104_1</td>\n",
       "      <td>traj_0000a8602cf2def930488dee7cdad104_1_1</td>\n",
       "      <td>-0.400807</td>\n",
       "      <td>-0.408314</td>\n",
       "      <td>-0.496767</td>\n",
       "      <td>-0.481641</td>\n",
       "      <td>-0.360753</td>\n",
       "      <td>-0.481641</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000a8602cf2def930488dee7cdad104_1</td>\n",
       "      <td>traj_0000a8602cf2def930488dee7cdad104_1_2</td>\n",
       "      <td>-0.377467</td>\n",
       "      <td>-0.350515</td>\n",
       "      <td>-0.482237</td>\n",
       "      <td>-0.484201</td>\n",
       "      <td>-0.287116</td>\n",
       "      <td>-0.484201</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000a8602cf2def930488dee7cdad104_1</td>\n",
       "      <td>traj_0000a8602cf2def930488dee7cdad104_1_3</td>\n",
       "      <td>-0.326408</td>\n",
       "      <td>-0.321582</td>\n",
       "      <td>-0.482040</td>\n",
       "      <td>-0.484307</td>\n",
       "      <td>-0.283475</td>\n",
       "      <td>-0.484307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000a8602cf2def930488dee7cdad104_1</td>\n",
       "      <td>traj_0000a8602cf2def930488dee7cdad104_1_4</td>\n",
       "      <td>2.255426</td>\n",
       "      <td>2.196077</td>\n",
       "      <td>-0.481575</td>\n",
       "      <td>-0.482700</td>\n",
       "      <td>-0.263699</td>\n",
       "      <td>-0.482700</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 hash  \\\n",
       "0  0000a8602cf2def930488dee7cdad104_1   \n",
       "1  0000a8602cf2def930488dee7cdad104_1   \n",
       "2  0000a8602cf2def930488dee7cdad104_1   \n",
       "3  0000a8602cf2def930488dee7cdad104_1   \n",
       "4  0000a8602cf2def930488dee7cdad104_1   \n",
       "\n",
       "                               trajectory_id  time_entry  time_exit   x_entry  \\\n",
       "0  traj_0000a8602cf2def930488dee7cdad104_1_0   -0.411531  -0.419661 -0.360248   \n",
       "1  traj_0000a8602cf2def930488dee7cdad104_1_1   -0.400807  -0.408314 -0.496767   \n",
       "2  traj_0000a8602cf2def930488dee7cdad104_1_2   -0.377467  -0.350515 -0.482237   \n",
       "3  traj_0000a8602cf2def930488dee7cdad104_1_3   -0.326408  -0.321582 -0.482040   \n",
       "4  traj_0000a8602cf2def930488dee7cdad104_1_4    2.255426   2.196077 -0.481575   \n",
       "\n",
       "    y_entry    x_exit    y_exit  label  \n",
       "0 -0.377866  2.485085 -0.377866      0  \n",
       "1 -0.481641 -0.360753 -0.481641      0  \n",
       "2 -0.484201 -0.287116 -0.484201      0  \n",
       "3 -0.484307 -0.283475 -0.484307      0  \n",
       "4 -0.482700 -0.263699 -0.482700      0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "small = True\n",
    "if small == True:\n",
    "    df_train = df_train.head(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the following step tells the distribution of number of trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create all_trajs, which stores every trajectory in a list\n",
    "\n",
    "# create a trajectory dictionary\n",
    "# {key: \"hash\" value: [\"x_entry\",\"y_entry\",\"x_exit\",\"y_exit\",\"time_entry\",\"time_exit\"] }\n",
    "\n",
    "whole_dict = {}\n",
    "all_trajs = []\n",
    "for index, row in df_train.iterrows():\n",
    "    \n",
    "    all_trajs.append([row[\"x_entry\"],row[\"y_entry\"],row[\"x_exit\"],row[\"y_exit\"],row[\"time_entry\"],row[\"time_exit\"]])\n",
    "   \n",
    "    if row[\"hash\"] not in whole_dict:\n",
    "        whole_dict[row[\"hash\"]] = []\n",
    "    whole_dict[row[\"hash\"]].append([row[\"x_entry\"],row[\"y_entry\"],row[\"x_exit\"],row[\"y_exit\"],row[\"time_entry\"],row[\"time_exit\"]])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "lst = [len(value) for value in whole_dict.values()]\n",
    "count = Counter(lst)\n",
    "num_traj_distribution = count.most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the following code treat all the trajectory equally, i.e., there is no ID difference. the batch size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preparation\n",
    "X_train = all_trajs\n",
    "y_train = df_train[\"label\"].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility for getting prediction accuracy\n",
    "def get_correct_and_accuracy(y_pred, y):\n",
    "    # y_pred is the nxC prediction scores\n",
    "    # give the number of correct and the accuracy\n",
    "    n = y.shape[0]\n",
    "    # find the prediction class label\n",
    "    _ ,pred_class = y_pred.max(dim=1)\n",
    "    correct = (pred_class == y).sum().item()\n",
    "    return correct ,correct/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes, input_size, hidden_size, num_layers,batch_size):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.num_layers = num_layers\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.sequence_length = 1\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.rnn = nn.RNN(input_size=6, hidden_size=64, batch_first=True)\n",
    "        self.fc = nn.Linear(self.hidden_size,2)\n",
    "        self.hidden = self.init_hidden()\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        # Reshape input\n",
    "        x = x.reshape(self.batch_size, self.sequence_length, self.input_size)\n",
    "\n",
    "        # Propagate input through RNN\n",
    "        # Input: (batch, seq_len, input_size)\n",
    "        x, self.hidden = self.rnn(x, self.hidden)\n",
    "        x = self.fc(x)\n",
    "        x = F.Softmax(x)\n",
    "        x = torch.argmax(x, dim=1)\n",
    "        \n",
    "        return x\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return(torch.zeros(self.num_layers, self.batch_size, self.hidden_size),   \n",
    "                torch.zeros(self.num_layers, self.batch_size, self.hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate RNN model\n",
    "num_classes = 2\n",
    "input_size = 6\n",
    "hidden_size=64\n",
    "num_layers = 2\n",
    "batch_size = 64\n",
    "\n",
    "rnn = RNN(num_classes, input_size, hidden_size, num_layers, batch_size)\n",
    "\n",
    "\n",
    "# Set loss and optimizer function\n",
    "# CrossEntropyLoss = LogSoftmax + NLLLoss\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=0.005)\n",
    "\n",
    "# X and Y preparation\n",
    "X_train_tensor = Tensor(all_trajs)\n",
    "Y_train_tensor = Tensor(y_train).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-4082f2b56029>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-2d836189c5cf>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# Propagate input through RNN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# Input: (batch, seq_len, input_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0mflat_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         func = self._backend.RNN(\n\u001b[1;32m    180\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    149\u001b[0m                               'Expected hidden[1] size {}, got {}')\n\u001b[1;32m    150\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m             \u001b[0mcheck_hidden_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_hidden_size\u001b[0;34m(hx, expected_hidden_size, msg)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcheck_hidden_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Expected hidden size {}, got {}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "x = X_train_tensor[:64]\n",
    "y_pred =rnn(x)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An alternative way, LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, batch_size, output_dim=1, num_layers=2, drop_prob = 0.6, lr= 0.005):\n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.num_layers = num_layers\n",
    "        dropout = drop_prob\n",
    "        \n",
    "        # define LSTM\n",
    "        self.lstm = nn.LSTM(\n",
    "                            self.input_dim, \n",
    "                            self.hidden_dim, \n",
    "                            self.num_layers,\n",
    "                            dropout = drop_prob\n",
    "            #batch_first = True\n",
    "                            )\n",
    "        \n",
    "        # define a dropout layper\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Define the final fc output layer\n",
    "        self.fc = nn.Linear(self.hidden_dim, output_dim)\n",
    "        \n",
    "        # initialize the weights\n",
    "        # self.init_weights()\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "                \n",
    "        # Reshape input (batch first)\n",
    "        # x = x.view(self.batch_size, 1, self.input_dim)\n",
    "\n",
    "\n",
    "        # get x and the hidden state from the lstm\n",
    "        x = self.lstm(x.reshape(self.batch_size,-1,6))\n",
    "        print(\"Type of x:\",type(x))\n",
    "        print(\"x:\",x)\n",
    "        # pass x through the dropout layer\n",
    "        self.dropout(0.6)\n",
    "        \n",
    "        # reshape it for the last linear fully connected layer\n",
    "        # x = x.view(-1,self.hidden_dim)\n",
    "        # x = self.fc(x)\n",
    "        x = self.fc(x.reshape(-1,output_dim))\n",
    "        return x\n",
    "        \n",
    "    def init_hidden(self):\n",
    "        # This is what we'll initialise our hidden state as\n",
    "        return (torch.zeros(self.num_layers, self.batch_size, self.hidden_dim),\n",
    "                torch.zeros(self.num_layers, self.batch_size, self.hidden_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init network\n",
    "lstm = LSTM(6,64,64)\n",
    "print('model structure: ', lstm)\n",
    "# init optimizer\n",
    "optimizer = optim.Adam(lstm.parameters(),lr = 0.005)\n",
    "# set loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "X_train_tensor = Tensor(X_train)\n",
    "# X_val_tensor = T\n",
    "y_train_tensor = Tensor(y_train).long() \n",
    "# y_val_tensor = Tensor(y_val).long()\n",
    "\n",
    "\n",
    "# prepare for mini-batch stochastic gradient descent\n",
    "n_iteration = 40\n",
    "batch_size = 64\n",
    "n_data = X_train_tensor.shape[0]\n",
    "n_batch = int(np.ceil(n_data/batch_size))\n",
    "\n",
    "\n",
    "\n",
    "print('X train tensor shape:', X_train_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## start \n",
    "train_loss_list = np.zeros(n_iteration)\n",
    "train_accu_list = np.zeros(n_iteration)\n",
    "val_loss_list = np.zeros(n_iteration)\n",
    "val_accu_list = np.zeros(n_iteration)\n",
    "\n",
    "hidden = lstm.init_hidden()\n",
    "for i in range(n_iteration):\n",
    "    # first get a minibatch of data\n",
    "    \n",
    "    total_train_loss = 0\n",
    "    total_train_acc = 0\n",
    "    \n",
    "    for j in range(n_batch):\n",
    "        batch_start_index = j*batch_size\n",
    "        # get data batch from the normalized data\n",
    "        X_batch = X_train_tensor[batch_start_index:batch_start_index+batch_size]\n",
    "        print(\"x\",X_batch.shape)\n",
    "        \n",
    "        # get ground truth label y\n",
    "        y_batch = y_train_tensor[batch_start_index:batch_start_index+batch_size]\n",
    "        \n",
    "        y_pred = lstm.forward(X_batch)\n",
    "        print(\"y:\", y_pred)\n",
    "        loss = criterion(y_pred,y_batch)\n",
    "        total_train_loss += loss\n",
    "        _ , accu = get_correct_and_accuracy(y_pred,y_batch)\n",
    "        total_train_acc += accu\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    # y_val_pred = conv_net.forward(X_val_tensor)\n",
    "    ave_train_loss = total_train_loss/n_batch\n",
    "    train_accu = total_train_acc/n_batch\n",
    "    # val_loss = criterion(y_val_pred,y_val_tensor)\n",
    "    # _,val_accu = get_correct_and_accuracy(y_val_pred,y_val_tensor)\n",
    "        \n",
    "        \n",
    "    #print(\"Iter %d ,Train loss: %.3f, Train acc: %.3f, Val loss: %.3f, Val acc: %.3f\"  %(i ,ave_train_loss, train_accu, val_loss, val_accu)) \n",
    "    ## add to the logs so that we can use them later for plotting\n",
    "    train_loss_list[i] = ave_train_loss\n",
    "    train_accu_list[i] = train_accu\n",
    "    #val_loss_list[i] =  val_loss\n",
    "    #val_accu_list[i] =  val_accu\n",
    "    print(\"ave_train_loss:\",ave_train_loss)\n",
    "    print(\"train_accuracy:\",train_accu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
